{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "import numpy as np\n",
    "\n",
    "from python.notebooks.backpropagation import Activation\n",
    "\n",
    "\n",
    "class FeedForward:\n",
    "    def __init__(self, layers: Sequence[int], activation: Activation):\n",
    "        if isinstance(layers, str) or not isinstance(layers, (list, tuple)):\n",
    "            raise ValueError(\"layers must be a list or tuple\")\n",
    "        if not issubclass(activation.__class__, Activation):\n",
    "            raise ValueError(\"activation must be a subclass of Activation\")\n",
    "\n",
    "        self.layers = layers\n",
    "        self.activation = activation\n",
    "        self.weights = self._generate_weights()\n",
    "        self.biases = [np.zeros(n) for n in self.layers[1:]]\n",
    "        self.inputs = [np.zeros(n) for n in self.layers]\n",
    "        self.outputs = [np.zeros(n) for n in self.layers]\n",
    "        self.errors = [np.zeros(n) for n in self.layers]\n",
    "\n",
    "    def _generate_weights(self) -> Sequence[Sequence[float]]:\n",
    "        return [np.random.rand(self.layers[i], self.layers[i + 1]) * 2 - .5 for i in\n",
    "                np.arange(len(self.layers) - 1)]\n",
    "\n",
    "    def forward_pass(self, inputs: Sequence[float]):\n",
    "        self.inputs[0] = inputs\n",
    "        self.outputs[0] = inputs\n",
    "        for i in np.arange(1, len(self.layers)):\n",
    "            self.inputs[i] = np.dot(self.outputs[i - 1], self.weights[i - 1]) + self.biases[i - 1]\n",
    "            self.outputs[i] = self.activation.apply(self.inputs[i])\n",
    "\n",
    "    def backward_pass(self, outputs: Sequence[float]):\n",
    "        self.errors[-1]\n",
    "\n",
    "    def print_state(self):\n",
    "        print(self.weights)\n",
    "        print(self.biases)\n",
    "        print(self.inputs)\n",
    "        print(self.outputs)\n",
    "        print(self.errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T: 0\n[array([[ 0.89183456,  1.20015314,  0.97703755],\n       [ 0.54903001,  1.27525754,  1.37904885]]), array([[ 0.24221623],\n       [ 0.64603191],\n       [-0.02179792]])]\n[array([ 0.,  0.,  0.]), array([ 0.])]\n[array([ 0.,  0.]), array([ 0.,  0.,  0.]), array([ 0.])]\n[array([ 0.,  0.]), array([ 0.,  0.,  0.]), array([ 0.])]\n[array([ 0.,  0.]), array([ 0.,  0.,  0.]), array([ 0.])]\nT: 1\n[array([[ 0.89183456,  1.20015314,  0.97703755],\n       [ 0.54903001,  1.27525754,  1.37904885]]), array([[ 0.24221623],\n       [ 0.64603191],\n       [-0.02179792]])]\n[array([ 0.,  0.,  0.]), array([ 0.])]\n[[0.5, 1.5], array([ 1.2694623 ,  2.51296288,  2.55709204]), array([ 1.87519929])]\n[[0.5, 1.5], [1.2694622976175007, 2.5129628778910269, 2.557092043757057], [1.875199291994033]]\n[array([ 0.,  0.]), array([ 0.,  0.,  0.]), array([ 0.])]\n"
     ]
    }
   ],
   "source": [
    "from python.notebooks.backpropagation import RectifiedLinearUnit\n",
    "\n",
    "net = FeedForward([2, 3, 1], RectifiedLinearUnit())\n",
    "print(\"T: 0\")\n",
    "net.print_state()\n",
    "net.forward_pass([.5, 1.5])\n",
    "print(\"T: 1\")\n",
    "net.print_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.weights[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}